{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import pickle\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_XGB_1124', 'rb') as f:\n",
    "    train_all = pickle.load(f)\n",
    "with open('test_XGB_1124', 'rb') as f:\n",
    "    test_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('files/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.insert(0, 'predicted', 0)\n",
    "submission.insert(0, 'meter_reading', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "\n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "#             print(\"dtype after: \",props[col].dtype)\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cffb91fad9a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNAlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mem_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "submission, NAlist = reduce_mem_usage(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_all.shape)\n",
    "print(test_all.shape)\n",
    "display(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(test_all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalerror(preds, actual):\n",
    "    preds[preds<0] = 0\n",
    "    return math.sqrt(np.square(np.log(preds+1)-np.log(actual+1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_real(X, y, X_test, rounds):\n",
    "#     rmsle to rmse\n",
    "    y = np.log(y+1)\n",
    "    params = {\n",
    "        'objective' : 'reg:squarederror',\n",
    "#         'nthread' : 8,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'eta' : 0.1,\n",
    "        'min_child_weight' : 3,\n",
    "#         'lambda' : 2\n",
    "        'max_depth' : 8\n",
    "        \n",
    "    }\n",
    "    num_rounds = rounds\n",
    "    plst = params.items()\n",
    "    dtrain = xgb.DMatrix( data = X.values, label = y.values)\n",
    "    del X,y\n",
    "    gc.collect()\n",
    "    model = xgb.train(plst, dtrain, num_rounds)\n",
    "    del dtrain\n",
    "    gc.collect()\n",
    "    # predict \n",
    "    l = X_test.shape[0]\n",
    "    preds = np.array([])\n",
    "    for i in range(5):\n",
    "        a = int(l*i/5)\n",
    "        b = int(l*(i+1)/5)\n",
    "        X_test2 = X_test.iloc[a:b]\n",
    "        dtest = xgb.DMatrix( data = X_test2.values)\n",
    "        preds2 = model.predict(dtest)\n",
    "        preds = np.concatenate((preds, preds2), axis=None)\n",
    "#     rmsle to rmse\n",
    "    preds = np.exp(preds) - 1\n",
    "    preds[preds<0] = 0\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train,test,rounds):\n",
    "    tick = time.time()\n",
    "    y_validall = []\n",
    "    y_predsall = []\n",
    "\n",
    "    y = train['meter_reading']\n",
    "    train = train.drop('meter_reading', axis=1)\n",
    "    #   for learn2\n",
    "    \n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(train, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "#     (score,preds) = learn2(X_train, X_valid, y_train, y_valid )\n",
    "\n",
    "#     y_validall.append(y_valid.values)\n",
    "#     y_predsall.append(preds)\n",
    "    \n",
    "#     y_validall2 = np.concatenate( y_validall, axis=0 )\n",
    "#     y_predsall2 = np.concatenate( y_predsall, axis=0 )\n",
    "#     print(evalerror(y_validall2,y_predsall2))\n",
    "    \n",
    "#     tock = time.time()\n",
    "#     print('Time used : {}'.format(tock-tick))\n",
    "    \n",
    "    #   for learn_real\n",
    "    y_row = test['row_id']\n",
    "    test = test.drop('row_id', axis=1)\n",
    "    preds = learn_real(train, y, test, rounds)\n",
    "    tock = time.time()\n",
    "    print('Time used : {}'.format(tock-tick))\n",
    "    \n",
    "    return(y_row,preds)\n",
    "\n",
    "    # print(y_predsall)\n",
    "    # with open('y_predsall1105_2', 'wb') as f:\n",
    "    #     pickle.dump(y_predsall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_building = [778,1099]\n",
    "split_siteid = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\n",
    "'building_id',\n",
    "'meter',\n",
    "'timestamp',\n",
    "# 'meter_reading',\n",
    "'site_id',\n",
    "'cloud_coverage',\n",
    "# 'precip_depth_1_hr',\n",
    "# 'sea_level_pressure'\n",
    "]\n",
    "\n",
    "drop_col_valid = [\n",
    "'building_id',\n",
    "'meter',\n",
    "# 'timestamp',\n",
    "# 'meter_reading',\n",
    "'site_id',\n",
    "'cloud_coverage',\n",
    "# 'precip_depth_1_hr',\n",
    "# 'sea_level_pressure'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_valid(X, rounds):\n",
    "    tick = time.time()\n",
    "    X1 = X.query('(timestamp <= \"2016-05-01\")')\n",
    "    X2 = X.query('(timestamp >= \"2016-09-01\")')\n",
    "    y1 = X1['meter_reading']\n",
    "    y2 = X2['meter_reading']\n",
    "    X1 = X1.drop(['meter_reading','timestamp'],axis=1)\n",
    "    X2 = X2.drop(['meter_reading','timestamp'],axis=1)\n",
    "    y1 = np.log(y1+1)\n",
    "    y2 = np.log(y2+1)\n",
    "    params = {\n",
    "        'objective' : 'reg:squarederror',\n",
    "#         'nthread' : 8,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'eta' : 0.1,\n",
    "        'min_child_weight' : 3,\n",
    "#         'lambda' : 2\n",
    "        'max_depth' : 8\n",
    "        \n",
    "    }\n",
    "    plst = params.items()\n",
    "    dtrain = xgb.DMatrix( data = X1.values, label = y1.values)\n",
    "    dtest = xgb.DMatrix( data = X2.values)\n",
    "#     num_rounds = 100\n",
    "    model = xgb.train(plst, dtrain, rounds)\n",
    "\n",
    "    # predict \n",
    "    y2_preds = model.predict(dtest)\n",
    "    y2_preds = np.exp(y2_preds) - 1\n",
    "    y2 = np.exp(y2) - 1\n",
    "    y2_preds[y2_preds<0] = 0\n",
    "    score = evalerror(y2,y2_preds)\n",
    "    print(score)\n",
    "    tock = time.time()\n",
    "    print(tock-tick)\n",
    "    return (y2,y2_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter 0\n",
      "Time used : 211.14210605621338\n",
      "Meter 1\n",
      "Time used : 81.20705080032349\n",
      "Meter 2\n",
      "Time used : 58.287596225738525\n",
      "Meter 3\n",
      "Time used : 35.40911936759949\n"
     ]
    }
   ],
   "source": [
    "y2_all = np.array([])\n",
    "y2_allpreds =  np.array([])\n",
    "for meter in range(0,4):\n",
    "    print('Meter {}'.format(meter))\n",
    "    train_meter = train_all[train_all['meter'] == meter]\n",
    "    train = train_meter[~train_meter['building_id'].isin(split_building)]\n",
    "    train = train[~train['site_id'].isin(split_siteid)]\n",
    "    \n",
    "    test_meter = test_all[test_all['meter'] == meter]\n",
    "    test = test_meter[~test_meter['building_id'].isin(split_building)]\n",
    "    test = test[~test['site_id'].isin(split_siteid)]\n",
    "    del train_meter\n",
    "    del test_meter\n",
    "    gc.collect()\n",
    "#     for validation\n",
    "#     train.drop(drop_col_valid,axis=1,inplace=True)\n",
    "#     (y2,y2_preds) = learn_valid(train,500)\n",
    "#     y2_all = np.concatenate((y2_all, y2), axis=None) \n",
    "#     y2_allpreds = np.concatenate((y2_allpreds, y2_preds), axis=None)\n",
    "#     for learn\n",
    "    train.drop(drop_col,axis=1,inplace=True)\n",
    "    test.drop(drop_col,axis=1,inplace=True)\n",
    "    (row,preds) = predict(train,test,500)\n",
    "    del train,test\n",
    "    gc.collect()\n",
    "\n",
    "    row = row.values.astype(int)\n",
    "    submission.at[row,'predicted'] = 1\n",
    "    submission.at[row,'meter_reading'] = preds\n",
    "    del row, preds\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 0\n",
      "8773\n",
      "Time used : 6.453373670578003\n",
      "778 1\n",
      "8084\n",
      "Time used : 6.646116018295288\n",
      "1099 0\n",
      "8781\n",
      "Time used : 6.677650690078735\n",
      "1099 2\n",
      "8783\n",
      "Time used : 6.505289316177368\n"
     ]
    }
   ],
   "source": [
    "# for split_id\n",
    "for building in split_building:\n",
    "    for meter in range(0,4):\n",
    "        train = train_all[train_all['building_id'] == building]\n",
    "        test = test_all[test_all['building_id'] == building]\n",
    "        train = train[train['meter'] == meter]\n",
    "        test = test[test['meter'] == meter]\n",
    "        if train.shape[0] == 0:\n",
    "            continue\n",
    "        print(building,meter)\n",
    "        print(train.shape[0])\n",
    "        train.drop(drop_col,axis=1,inplace=True)\n",
    "        test.drop(drop_col,axis=1,inplace=True)\n",
    "#         remove col with one value\n",
    "        nunique = train.apply(pd.Series.nunique)\n",
    "        cols_to_drop = nunique[nunique == 1].index\n",
    "        train.drop(cols_to_drop, axis=1)\n",
    "        test.drop(cols_to_drop, axis=1)\n",
    "#         \n",
    "        (row, preds) = predict(train, test,500)\n",
    "        del train, test\n",
    "        gc.collect()\n",
    "        row = row.values.astype(int)\n",
    "        submission.at[row,'predicted'] = 1\n",
    "        submission.at[row,'meter_reading'] = preds\n",
    "        del row, preds\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 102745\n",
      "Time used : 10.397579908370972\n",
      "1 128456\n",
      "Time used : 11.432095766067505\n",
      "2 102607\n",
      "Time used : 10.565889120101929\n",
      "3 25834\n",
      "Time used : 7.5759758949279785\n"
     ]
    }
   ],
   "source": [
    "# for split_siteid\n",
    "for site_id in split_siteid:\n",
    "    for meter in range(0,4):\n",
    "        train = train_all[train_all['site_id'] == site_id]\n",
    "        test = test_all[test_all['site_id'] == site_id]\n",
    "        train = train[train['meter'] == meter]\n",
    "        test = test[test['meter'] == meter]\n",
    "        if train.shape[0] == 0:\n",
    "            continue\n",
    "        print(meter,train.shape[0])\n",
    "        train.drop(drop_col,axis=1,inplace=True)\n",
    "        test.drop(drop_col,axis=1,inplace=True)\n",
    "#         remove col with one value\n",
    "        nunique = train.apply(pd.Series.nunique)\n",
    "        cols_to_drop = nunique[nunique == 1].index\n",
    "        train.drop(cols_to_drop, axis=1)\n",
    "        test.drop(cols_to_drop, axis=1)\n",
    "#         \n",
    "        (row, preds) = predict(train, test,500)\n",
    "        del train, test\n",
    "        gc.collect()\n",
    "        row = row.values.astype(int)\n",
    "        submission.at[row,'predicted'] = 1\n",
    "        submission.at[row,'meter_reading'] = preds\n",
    "        del row, preds\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sub', 'wb') as f:\n",
    "    pickle.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
