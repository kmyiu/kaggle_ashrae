{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "import time\n",
    "# import xgboost as xgb\n",
    "import gc\n",
    "import pickle\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_LGBM_1209', 'rb') as f:\n",
    "    train_all = pickle.load(f)\n",
    "with open('test_LGBM_1209', 'rb') as f:\n",
    "    test_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('files/test.csv')\n",
    "submission.insert(0, 'predicted', 0)\n",
    "submission.insert(0, 'meter_reading', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 1908.7647705078125  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  676.0209350585938  MB\n",
      "This is  35.416670796933424 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "submission, NAlist = reduce_mem_usage(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19770715, 24)\n",
      "(41498571, 24)\n"
     ]
    }
   ],
   "source": [
    "print(train_all.shape)\n",
    "print(test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id            uint16\n",
      "meter                   uint8\n",
      "timestamp              object\n",
      "meter_reading         float32\n",
      "site_id                 uint8\n",
      "primary_use             uint8\n",
      "square_feet            uint32\n",
      "floor_count             uint8\n",
      "age                     uint8\n",
      "weekday                 uint8\n",
      "hour                    uint8\n",
      "month                   uint8\n",
      "air_temperature       float32\n",
      "cloud_coverage         uint16\n",
      "dew_temperature       float32\n",
      "precip_depth_1_hr     float32\n",
      "sea_level_pressure    float32\n",
      "wind_direction          uint8\n",
      "wind_speed            float32\n",
      "humidity              float32\n",
      "apparent_temp         float32\n",
      "min_temperature       float32\n",
      "max_temperature       float32\n",
      "mean_temperature      float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(train_all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id                 uint32\n",
      "building_id            uint16\n",
      "meter                   uint8\n",
      "timestamp              object\n",
      "site_id                 uint8\n",
      "primary_use             uint8\n",
      "square_feet            uint32\n",
      "floor_count             uint8\n",
      "age                     uint8\n",
      "weekday                 uint8\n",
      "hour                    uint8\n",
      "month                   uint8\n",
      "air_temperature       float32\n",
      "cloud_coverage         uint16\n",
      "dew_temperature       float32\n",
      "precip_depth_1_hr     float32\n",
      "sea_level_pressure    float32\n",
      "wind_direction          uint8\n",
      "wind_speed            float32\n",
      "humidity              float32\n",
      "apparent_temp         float32\n",
      "min_temperature       float32\n",
      "max_temperature       float32\n",
      "mean_temperature      float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(test_all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalerror(preds, actual):\n",
    "    preds[preds<0] = 0\n",
    "    return math.sqrt(np.square(np.log(preds+1)-np.log(actual+1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_building = [778,1099]\n",
    "split_siteid = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_test = [\n",
    "    'row_id','meter','timestamp'\n",
    "    ,'cloud_coverage'\n",
    "]\n",
    "\n",
    "drop_col_valid = [\n",
    "# 'building_id',\n",
    "'meter',\n",
    "# 'timestamp',\n",
    "# 'meter_reading',\n",
    "# 'site_id',\n",
    "'cloud_coverage',\n",
    "# 'precip_depth_1_hr',\n",
    "# 'sea_level_pressure'\n",
    "]\n",
    "\n",
    "categorical_features_valid = ['building_id','primary_use','site_id','age','weekday','hour','wind_direction']\n",
    "categorical_features = ['building_id','primary_use','site_id','age','month','weekday','hour','wind_direction']\n",
    "# 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_valid(X,test):\n",
    "    tick = time.time()\n",
    "    X = X.drop(['min_temperature','max_temperature'],axis=1)\n",
    "    test = test.drop(['min_temperature','max_temperature'],axis=1)\n",
    "    X1 = X.query('(timestamp <= \"2016-05-01\")')\n",
    "    X2 = X.query('(timestamp >= \"2016-09-01\")')\n",
    "    if X1.empty or X2.empty:\n",
    "        a = np.array([])\n",
    "        b = np.array([])\n",
    "        return (a,b)\n",
    "    y1 = X1['meter_reading']\n",
    "    y2 = X2['meter_reading']\n",
    "    X1 = X1.drop(['meter_reading','timestamp','site_id'],axis=1)\n",
    "    X2 = X2.drop(['meter_reading','timestamp','site_id'],axis=1)\n",
    "    X1 = X1.drop(['month'],axis=1)\n",
    "    X2 = X2.drop(['month'],axis=1)\n",
    "    y1 = np.log(y1+1)\n",
    "    y2 = np.log(y2+1)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"num_leaves\": 1280,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.85,\n",
    "        \"reg_lambda\": 2,\n",
    "        \"metric\": \"rmse\",\n",
    "#         \"device\": \"gpu\",\n",
    "    }\n",
    "\n",
    "#     kf = KFold(n_splits=3)\n",
    "#     models = []\n",
    "#     for train_index,test_index in kf.split(features):\n",
    "#         train_features = features.loc[train_index]\n",
    "#         train_target = target.loc[train_index]\n",
    "\n",
    "#         test_features = features.loc[test_index]\n",
    "#         test_target = target.loc[test_index]\n",
    "#     print(X1.columns)\n",
    "#     print(X2.columns)\n",
    "    if list(X1.columns) != list(X2.columns):\n",
    "        print('error in valid')\n",
    "        print(X1.columns)\n",
    "        print(X2.columns)\n",
    "        return 0\n",
    "    categorical_features_valid2 = []\n",
    "    categorical_features2 = []\n",
    "    for cat in categorical_features_valid:\n",
    "        if cat in X1.columns:\n",
    "            categorical_features_valid2.append(cat)\n",
    "    \n",
    "    d_training = lgb.Dataset(X1, label=y1,categorical_feature=categorical_features_valid2, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(X2, label=y2,categorical_feature=categorical_features_valid2, free_raw_data=False)\n",
    "\n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=400, valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "    models.append(model)\n",
    "#     del train_features, train_target, test_features, test_target, d_training, d_test\n",
    "    gc.collect()\n",
    "#     return 0\n",
    "#     for cal cv score\n",
    "#     y2_preds = model.predict(X2, num_iteration=model.best_iteration)\n",
    "#     y2 = np.exp(y2) - 1\n",
    "#     y2_preds = np.exp(y2_preds) - 1\n",
    "#     y2_preds[y2_preds<0] = 0\n",
    "#     tock = time.time()\n",
    "#     print(tock-tick)\n",
    "#     return (y2,y2_preds) \n",
    "\n",
    "# for real\n",
    "    best_iteration = model.best_iteration\n",
    "    y = X['meter_reading']\n",
    "    y = np.log(y+1)\n",
    "    X = X.drop(['meter_reading','timestamp'],axis=1)\n",
    "    for cat in categorical_features:\n",
    "        if cat in X.columns:\n",
    "            categorical_features2.append(cat)\n",
    "    print(X.columns)\n",
    "    print(test.columns)\n",
    "#     return 0\n",
    "    d_training = lgb.Dataset(X, label=y,categorical_feature=categorical_features2, free_raw_data=False)\n",
    "    if list(X.columns) != list(test.columns):\n",
    "        print('error in real train')\n",
    "        return 0\n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=best_iteration)\n",
    "    preds = model.predict(test)\n",
    "    preds = np.exp(preds) - 1\n",
    "    preds[preds<0] = 0\n",
    "    tock = time.time()\n",
    "    print(tock-tick)\n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn2(train_site):\n",
    "    nunique = train_site.apply(pd.Series.nunique)\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    train.drop(cols_to_drop, axis=1)\n",
    "    test.drop(cols_to_drop, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.573696\tvalid_1's rmse: 0.952961\n",
      "[50]\ttraining's rmse: 0.35632\tvalid_1's rmse: 0.924503\n",
      "[75]\ttraining's rmse: 0.297427\tvalid_1's rmse: 0.932728\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.393695\tvalid_1's rmse: 0.922186\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "110.94637823104858\n",
      "Meter 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.06008\tvalid_1's rmse: 1.62168\n",
      "[50]\ttraining's rmse: 0.736537\tvalid_1's rmse: 1.5629\n",
      "[75]\ttraining's rmse: 0.643355\tvalid_1's rmse: 1.57071\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 0.764055\tvalid_1's rmse: 1.56128\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "33.738094329833984\n",
      "Meter 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.07241\tvalid_1's rmse: 1.80546\n",
      "[50]\ttraining's rmse: 0.785221\tvalid_1's rmse: 1.77708\n",
      "[75]\ttraining's rmse: 0.701615\tvalid_1's rmse: 1.78445\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.837061\tvalid_1's rmse: 1.77415\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "20.164883613586426\n",
      "Meter 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.17614\tvalid_1's rmse: 1.94569\n",
      "[50]\ttraining's rmse: 0.91229\tvalid_1's rmse: 1.90023\n",
      "[75]\ttraining's rmse: 0.819249\tvalid_1's rmse: 1.90376\n",
      "[100]\ttraining's rmse: 0.761313\tvalid_1's rmse: 1.90543\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.892511\tvalid_1's rmse: 1.89955\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "15.331263065338135\n"
     ]
    }
   ],
   "source": [
    "y2_all = np.array([])\n",
    "y2_allpreds = np.array([])\n",
    "preds_all1 = []\n",
    "preds_all2 = []\n",
    "models = []\n",
    "for meter in range(0,4):\n",
    "    print('Meter {}'.format(meter))\n",
    "    train_meter = train_all[train_all['meter'] == meter]\n",
    "    train = train_meter[~train_meter['building_id'].isin(split_building)]\n",
    "    train = train[~train['site_id'].isin(split_siteid)]\n",
    "    \n",
    "    test_meter = test_all[test_all['meter'] == meter]\n",
    "    test = test_meter[~test_meter['building_id'].isin(split_building)]\n",
    "    test = test[~test['site_id'].isin(split_siteid)]\n",
    "    del train_meter\n",
    "    del test_meter\n",
    "    gc.collect()\n",
    "#     for validation\n",
    "    train.drop(drop_col_valid,axis=1,inplace=True)\n",
    "    row = test['row_id']\n",
    "    test.drop(drop_col_test,axis=1,inplace=True)\n",
    "    preds = learn_valid(train,test)\n",
    "    \n",
    "#     (y2,y2_preds) = learn_valid(train,test)\n",
    "#     y2_all = np.concatenate((y2_all, y2), axis=None) \n",
    "#     y2_allpreds = np.concatenate((y2_allpreds, y2_preds), axis=None)\n",
    "#     break\n",
    "    \n",
    "#     for learn\n",
    "    row = row.values.astype(int)\n",
    "    submission.at[row,'predicted'] = 1\n",
    "    submission.at[row,'meter_reading'] = preds\n",
    "    del row, preds\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y2_all = np.array([])\n",
    "# # y2_allpreds = np.array([])\n",
    "# models = []\n",
    "# for meter in range(0,4):\n",
    "#     print('Meter {}'.format(meter))\n",
    "#     train_meter = train_all[train_all['meter'] == meter]\n",
    "#     train = train_meter[~train_meter['building_id'].isin(split_building)]\n",
    "#     train = train[~train['site_id'].isin(split_siteid)]\n",
    "    \n",
    "#     test_meter = test_all[test_all['meter'] == meter]\n",
    "#     test = test_meter[~test_meter['building_id'].isin(split_building)]\n",
    "#     test = test[~test['site_id'].isin(split_siteid)]\n",
    "#     del train_meter\n",
    "#     del test_meter\n",
    "#     gc.collect()\n",
    "#     s = train['building_id'].unique()\n",
    "#     for build in s:\n",
    "#         print(build)\n",
    "#         t1 = train[train['building_id'] == build]\n",
    "#         t2 = test[test['building_id'] == build]\n",
    "#         t1.drop(drop_col_valid,axis=1,inplace=True)\n",
    "#         t2.drop(drop_col_test,axis=1,inplace=True)\n",
    "#         (y2,y2_preds) = learn_valid(t1,t2)\n",
    "#         y2_all = np.concatenate((y2_all, y2), axis=None) \n",
    "#         y2_allpreds = np.concatenate((y2_allpreds, y2_preds), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalerror(y2_all,y2_allpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for model in models:\n",
    "#     lgb.plot_importance(model)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 0\n",
      "8773\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.125685\tvalid_1's rmse: 0.193453\n",
      "[50]\ttraining's rmse: 0.076283\tvalid_1's rmse: 0.178241\n",
      "[75]\ttraining's rmse: 0.054845\tvalid_1's rmse: 0.175922\n",
      "[100]\ttraining's rmse: 0.0430767\tvalid_1's rmse: 0.17533\n",
      "[125]\ttraining's rmse: 0.0356037\tvalid_1's rmse: 0.175203\n",
      "[150]\ttraining's rmse: 0.0303244\tvalid_1's rmse: 0.175673\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's rmse: 0.0363096\tvalid_1's rmse: 0.174998\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "1.7999868392944336\n",
      "778 1\n",
      "8084\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.162481\tvalid_1's rmse: 7.04863\n",
      "[50]\ttraining's rmse: 0.156523\tvalid_1's rmse: 7.0403\n",
      "[75]\ttraining's rmse: 0.151798\tvalid_1's rmse: 7.03643\n",
      "[100]\ttraining's rmse: 0.146442\tvalid_1's rmse: 7.02921\n",
      "[125]\ttraining's rmse: 0.141806\tvalid_1's rmse: 7.02547\n",
      "[150]\ttraining's rmse: 0.137104\tvalid_1's rmse: 7.0227\n",
      "[175]\ttraining's rmse: 0.132837\tvalid_1's rmse: 7.02057\n",
      "[200]\ttraining's rmse: 0.128681\tvalid_1's rmse: 7.01666\n",
      "[225]\ttraining's rmse: 0.12448\tvalid_1's rmse: 7.01327\n",
      "[250]\ttraining's rmse: 0.120693\tvalid_1's rmse: 7.01032\n",
      "[275]\ttraining's rmse: 0.117033\tvalid_1's rmse: 7.00877\n",
      "[300]\ttraining's rmse: 0.11329\tvalid_1's rmse: 7.00707\n",
      "[325]\ttraining's rmse: 0.109455\tvalid_1's rmse: 7.00499\n",
      "[350]\ttraining's rmse: 0.106138\tvalid_1's rmse: 7.00348\n",
      "[375]\ttraining's rmse: 0.102737\tvalid_1's rmse: 7.0019\n",
      "[400]\ttraining's rmse: 0.0997075\tvalid_1's rmse: 6.99998\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.0997075\tvalid_1's rmse: 6.99998\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "4.610281467437744\n",
      "1099 0\n",
      "8781\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.149813\tvalid_1's rmse: 0.211071\n",
      "[50]\ttraining's rmse: 0.086303\tvalid_1's rmse: 0.175167\n",
      "[75]\ttraining's rmse: 0.0595457\tvalid_1's rmse: 0.166592\n",
      "[100]\ttraining's rmse: 0.045673\tvalid_1's rmse: 0.164233\n",
      "[125]\ttraining's rmse: 0.0367714\tvalid_1's rmse: 0.163368\n",
      "[150]\ttraining's rmse: 0.0309729\tvalid_1's rmse: 0.162921\n",
      "[175]\ttraining's rmse: 0.0265679\tvalid_1's rmse: 0.162879\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's rmse: 0.0313499\tvalid_1's rmse: 0.16283\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "2.208268642425537\n",
      "1099 2\n",
      "8783\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.47345\tvalid_1's rmse: 6.92416\n",
      "[50]\ttraining's rmse: 1.03918\tvalid_1's rmse: 7.32925\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 2.90643\tvalid_1's rmse: 5.76414\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "Index(['building_id', 'site_id', 'primary_use', 'square_feet', 'floor_count',\n",
      "       'age', 'weekday', 'hour', 'month', 'air_temperature', 'dew_temperature',\n",
      "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
      "       'wind_speed', 'humidity', 'apparent_temp', 'mean_temperature'],\n",
      "      dtype='object')\n",
      "0.16500115394592285\n"
     ]
    }
   ],
   "source": [
    "# for split_id\n",
    "for building in split_building:\n",
    "    for meter in range(0,4):\n",
    "        train = train_all[train_all['building_id'] == building]\n",
    "        test = test_all[test_all['building_id'] == building]\n",
    "        train = train[train['meter'] == meter]\n",
    "        test = test[test['meter'] == meter]\n",
    "        if train.shape[0] == 0:\n",
    "            continue\n",
    "        print(building,meter)\n",
    "        print(train.shape[0])\n",
    "#         \n",
    "        train.drop(drop_col_valid,axis=1,inplace=True)\n",
    "        row = test['row_id']\n",
    "        test.drop(drop_col_test,axis=1,inplace=True)\n",
    "#         remove col with one value\n",
    "        nunique = train.apply(pd.Series.nunique)\n",
    "        cols_to_drop = nunique[nunique == 1].index\n",
    "        train.drop(cols_to_drop, axis=1)\n",
    "        test.drop(cols_to_drop, axis=1)\n",
    "        \n",
    "        preds = learn_valid(train,test)\n",
    "#         \n",
    "        row = row.values.astype(int)\n",
    "        submission.at[row,'predicted'] = 1\n",
    "        submission.at[row,'meter_reading'] = preds\n",
    "        del row, preds\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split_siteid\n",
    "for site_id in split_siteid:\n",
    "    for meter in range(0,4):\n",
    "        train = train_all[train_all['site_id'] == site_id]\n",
    "        test = test_all[test_all['site_id'] == site_id]\n",
    "        train = train[train['meter'] == meter]\n",
    "        test = test[test['meter'] == meter]\n",
    "        if train.shape[0] == 0:\n",
    "            continue\n",
    "        print(meter,train.shape[0])\n",
    "        train.drop(drop_col_valid,axis=1,inplace=True)\n",
    "        row = test['row_id']\n",
    "        test.drop(drop_col_test,axis=1,inplace=True)\n",
    "#         remove col with one value\n",
    "        nunique = train.apply(pd.Series.nunique)\n",
    "        cols_to_drop = nunique[nunique == 1].index\n",
    "        train.drop(cols_to_drop, axis=1)\n",
    "        test.drop(cols_to_drop, axis=1)\n",
    "        \n",
    "        preds = learn_valid(train,test)\n",
    "#         \n",
    "        row = row.values.astype(int)\n",
    "        submission.at[row,'predicted'] = 1\n",
    "        submission.at[row,'meter_reading'] = preds\n",
    "        del row, preds\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sub2', 'wb') as f:\n",
    "    pickle.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
